{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DecimalType, DoubleType, FloatType, ArrayType\n",
    "# from decimal import Decimal\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "#for user defined funstions\n",
    "from pyspark.sql.functions import udf, col\n",
    "\n",
    "#for generating random numbers\n",
    "from random import randint, random\n",
    "#necessary for calculating root of discriminant\n",
    "from math import sqrt\n",
    "\n",
    "# Create Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"create df from dict\") \\\n",
    "    .master(\"local\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# instantiate Spark\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "#define column types\n",
    "schema = StructType([\n",
    "    StructField('a', DoubleType(), False),\n",
    "    StructField('b', DoubleType(), False),\n",
    "    StructField('c', DoubleType(), False),\n",
    "    StructField('d', DoubleType(), False),\n",
    "    StructField('x1', DoubleType(), True),\n",
    "    StructField('x2', DoubleType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2000000\n",
    "\n",
    "#generate coefficents a,b,c for quadratic equation a*x^2 + b*x + c\n",
    "vals = list()\n",
    "for i in range(n):\n",
    "    a = 20 * random() - 8\n",
    "    b = 10 * random() + 4\n",
    "    c = 6 * random()-7\n",
    "    d = b ** 2 - 4 * a * c\n",
    "    if d >= 0:\n",
    "        x1 = (-b - sqrt(d)) / 2 / a\n",
    "        x2 = (-b + sqrt(d)) / 2 / a\n",
    "    elif d == 0:\n",
    "        x1 = x2 = -b / 2 / a\n",
    "    else:\n",
    "        x1 = x2 = None\n",
    "    vals.append((a,b,c,d,x1,x2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create DataFrame\n",
    "df = spark.createDataFrame(vals, schema)\n",
    "# df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate value of quadratic function\n",
    "def f(x,a,b,c):\n",
    "    return a * x ** 2 + b * x + c\n",
    "\n",
    "#find root of quadratice equation in case it exists\n",
    "#by Binary search\n",
    "def solve_q_eq(left, right, a, b, c):\n",
    "    eps = 1.e-8\n",
    "    if f(right,a,b,c) >= 0:\n",
    "        while abs(right - left) > eps:\n",
    "            mid = (left + right) / 2\n",
    "            tmp = f(mid,a,b,c)\n",
    "            if tmp > 0:\n",
    "                right = mid\n",
    "            elif tmp < 0:\n",
    "                left = mid\n",
    "            else:\n",
    "                break\n",
    "    else:\n",
    "        while abs(right - left) > eps:\n",
    "            mid = (left + right) / 2\n",
    "            f_left = f(left,a,b,c)\n",
    "            tmp = f(mid,a,b,c)\n",
    "            if tmp > 0:\n",
    "                left = mid\n",
    "            elif tmp < 0:\n",
    "                right = mid\n",
    "            else:\n",
    "                break\n",
    "    return (mid)\n",
    "\n",
    "#use previously defined 'solve_q_eq' function for finding both roots\n",
    "#of quadratic equation\n",
    "def solve_q_eq_totally(a,b,c):\n",
    "    left = -20\n",
    "    right = 20\n",
    "    d = b ** 2 - 4 * a * c\n",
    "    if d >= 0:\n",
    "        x1 = solve_q_eq(left, right, a, b, c)\n",
    "        right = x1 - 0.01\n",
    "        x2 = solve_q_eq(left, right, a, b, c)\n",
    "    else:\n",
    "        x1 = None\n",
    "        x2 = None\n",
    "    return (x1, x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this schema is for outputs of function 'solve_udf' which is PySpark version\n",
    "# of 'solve_q_eq_totally'\n",
    "array_schema = StructType([\n",
    "    StructField('x1_calc', DoubleType(), nullable=True),\n",
    "    StructField('x2_calc', DoubleType(), nullable=True)\n",
    "    ])\n",
    "\n",
    "solve_udf = udf(lambda a,b,c: solve_q_eq_totally(a,b,c), array_schema)\n",
    "\n",
    "#save df and found roots column to new df2 DataFrame\n",
    "df2 = df.select('a', 'b', 'c','d', 'x1', 'x2', solve_udf('a', 'b', 'c').alias('roots'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2.select('roots.x2_calc').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.write.parquet(\"quadr_eq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sparkenv]",
   "language": "python",
   "name": "conda-env-sparkenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
